Install TF
-- mkdir terraform
-- cd terraform

=====================================================
Dynamic Block, Terraform Provisioners
====================================================


Provisioners
-----------
   -- Terraform provisioners are used to perform actions on a local or remote machine after a resource is created or updated.

   -- They are typically used for tasks such as configuring or installing software on a machine, which Terraform itself does not handle directly.

Types of Provisioners
---------------------

Terraform supports several types of provisioners:

local-exec:
**********

Executes a command locally on the machine where Terraform is run.
Useful for running scripts or commands that need to be executed locally.

remote-exec:
***********

Executes commands on a remote resource, such as an EC2 instance, after it has been created.
Useful for configuring instances or applying configurations remotely.

file:
****

Uploads files from the local machine to a remote resource.
Useful for transferring configuration files or scripts to a remote machine.

Examples:
--------

local-exec:  The "local-exec" provisioner runs commands on the local machine where Terraform is executed.
**********

In this example, the local-exec provisioner writes the instance ID to a file instance_id.txt on the local machine after the EC2 instance is created.

vi main.tf

resource "aws_instance" "example" {
  ami           = "ami-08ee1453725d19cdb"
  instance_type = "t2.micro"

  provisioner "local-exec" {
    command = "echo 'Instance ID: ${self.id}' > instance_id.txt"
  }
}

output "instance_id" {
  value = aws_instance.example.id
}


self.id will be available after the instance is created
The provisioner runs on the local machine, saving the instance ID to instance_id.txt.


-- terraform apply --auto-approve

-- ls  [you can see the txt got created locally]

-- terraform destroy  --auto-approve


Remote-Exec - The remote-exec provisioner runs commands on a remote resource. It typically requires a connection configuration.
**********

Example:
-------

From TF machine , we will connect remotely to another machine, for this we need to have pem file under ~/.ssh/id_rsa


-- vi ~/.ssh/id_rsa
copy paste pem file data


vi main.tf

resource "aws_instance" "example" {
  ami           = "ami-08ee1453725d19cdb"
  instance_type = "t2.micro"
  key_name      = "MyKey"
  tags = {
    Name = "ec2-instance"
  }
  provisioner "remote-exec" {
    inline = [
      "sudo yum update -y",
      "sudo yum install -y httpd",
      "sudo systemctl start httpd"
    ]

    connection {
      type        = "ssh"
      user        = "ec2-user"
      private_key = file("~/.ssh/id_rsa")
      host        = self.public_ip
    }
  }
}

-- terraform apply --auto-approve

-- terraform destroy  --auto-approve


File Provisioner - The file provisioner uploads files from the local machine to the remote resource.
***************

-- cd /tmp

-- vi remote_script.sh

#!/bin/bash

# Example commands to run on the remote instance
echo "Running remote script"

# Update the system
sudo yum update -y

# Install Apache HTTP Server
sudo yum install -y httpd

# Start and enable the Apache service
sudo systemctl start httpd
sudo systemctl enable httpd

# Write content to /var/www/html/index.html with sudo
echo "<html><h1>Welcome to Naresh IT ! AWS Infra created using Terraform in Mumbai Region!</h1></html>" | sudo tee /var/www/html/index.html > /dev/null


-------------------------------------------------------

vi main.tf

resource "aws_instance" "apache" {
  ami           = "ami-08ee1453725d19cdb"
  instance_type = "t2.micro"
  key_name      = "MyKey"
  tags = {
    Name = "ec2-apache"
  }

  provisioner "file" {
    source      = "remote_script.sh"
    destination = "/tmp/remote_script.sh"

    connection {
      type        = "ssh"
      user        = "ec2-user"
      private_key = file("~/.ssh/id_rsa")
      host        = self.public_ip
    }
  }

provisioner "remote-exec" {
    inline = [
      "chmod +x /tmp/remote_script.sh",
      "/tmp/remote_script.sh"
    ]

    connection {
      type        = "ssh"
      user        = "ec2-user"
      private_key = file("~/.ssh/id_rsa")
      host        = self.public_ip
    }
  }
}

output "instance_ip" {
  value = aws_instance.apache.public_ip
}

-- terraform apply --auto-approve

-- terraform destroy  --auto-approve


http://IP


Example 2:
-----------

vi userdata.sh

#!/bin/bash
sudo yum update -y
sudo yum install -y httpd
sudo service httpd start  
sudo systemctl enable httpd
echo "<h1>Welcome to Reyaz DevOps ! AWS Infra created using Terraform in Mumbai Region</h1>" > /var/www/html/index.html


vi main.tf

provider "aws" {
region = "ap-south-1"  
}
resource "aws_instance" "test" {
    ami = "ami-08ee1453725d19cdb"
    instance_type = "t2.micro"
    user_data= file("userdata.sh")
}

output "instance_ip" {
  value = aws_instance.test.public_ip
}


-- terraform apply --auto-approve

-- terraform destroy  --auto-approve

=================
Dynamic Block  - it is used to reduce the length of the block
=================

Example: Launch a new EC2 instance with security group allowed protocols 22 and 80, in this example we should create multiple ingress rules for multiple protocols

vi main.tf

provider "aws" {
  region = "ap-south-1"
}

# Security Group
resource "aws_security_group" "example_sg" {
  name        = "example-sg"
  description = "Security group for example EC2 instance"

  # Inbound rules
  ingress {
    description = "Allow SSH"
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    description = "Allow HTTP"
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  # Outbound rules
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name = "example-sg"
  }
}

# EC2 Instance
resource "aws_instance" "example" {
  ami           = "ami-08ee1453725d19cdb"  # Replace with your desired AMI ID
  instance_type = "t2.micro"
  key_name      = "MyKey"          # Replace with your SSH key name

  # Associate the security group with the EC2 instance
  vpc_security_group_ids = [aws_security_group.example_sg.id]

  tags = {
    Name = "ExampleInstance"
  }
}

# Output the public IP of the instance
output "instance_ip" {
  value = aws_instance.example.public_ip
}



-- terraform apply --auto-approve

-- terraform destroy  --auto-approve

---------------------------------------------------------

But instead writing multiple ingress rules, we can use dynamic block

Example 2:
-----------

vi main.tf


provider "aws" {
  region = "ap-south-1"
}

locals {
  ingress_rules = [{
    port        = 443
    description = "Ingress rules for port 443"
    },
    {
      port        = 80
      description = "Ingress rules for port 80"
    },
    {
      port        = 8080
      description = "Ingress rules for port 8080"

  }]
}

resource "aws_instance" "ec2_example" {
  ami                    = "ami-08ee1453725d19cdb"
  instance_type          = "t2.micro"
  vpc_security_group_ids = [aws_security_group.main.id]
  tags = {
    Name = "Terraform EC2"
  }
}

resource "aws_security_group" "main" {

  egress = [
    {
      cidr_blocks      = ["0.0.0.0/0"]
      description      = "*"
      from_port        = 0
      ipv6_cidr_blocks = []
      prefix_list_ids  = []
      protocol         = "-1"
      security_groups  = []
      self             = false
      to_port          = 0
  }]

  dynamic "ingress" {
    for_each = local.ingress_rules

    content {
      description = "*"
      from_port   = ingress.value.port
      to_port     = ingress.value.port
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }
  }

  tags = {
    Name = "terra sg"
  }
}


-- terraform apply --auto-approve

-- terraform destroy  --auto-approve


===============
Terraform MAP - Giving tags for resources, key and value
================


It  is a variable type used to pass key and value pair for resource.


vi main.tf

provider "aws" {
region = "ap-south-1"
}

resource "aws_instance" "three" {
  ami           = "ami-08ee1453725d19cdb"
  instance_type = "t2.micro"
  availability_zone = "ap-south-1a"
  tags = var.ec2_tags
}

variable "ec2_tags" {
description = ""
type = map(any)
default = {
Env = "prod"
Client = "Infy"
Name = "Taggingserver"
}
}


-- terraform apply --auto-approve

-- terraform destroy  --auto-approve


=============================
DATA-Source
==========================

In Terraform, a data source allows you to fetch information from existing resources or services that are external to your Terraform configuration.

Fetching Information About Existing Resources:
       
If you need to retrieve information about an existing resource that wasn't created by your Terraform configuration (e.g., an existing AWS VPC or EC2 AMI).

Example 1:  Below example is used to fetch the latest ami and assign to the EC2 instance
----------

vi main.tf

provider "aws" {
  region = "ap-south-1"
}

# Data source to fetch the latest Amazon Linux 2 AMI

data "aws_ami" "amazon_linux" {
  most_recent = true

  filter {
    name   = "name"
    values = ["amzn2-ami-hvm-*-x86_64-gp2"]
  }

  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }

  owners = ["137112412989"]  # Amazon's official AWS account ID for Amazon Linux
}

# EC2 instance using the fetched AMI
resource "aws_instance" "example" {
  ami           = data.aws_ami.amazon_linux.id
  instance_type = "t2.micro"
  key_name      = "MyKey"  # Replace with your SSH key name

  tags = {
    Name = "ExampleInstance"
  }
}

output "instance_ip" {
  value = aws_instance.example.public_ip
}


Example 2: To get the existing vpc and bucket details
---------------------------------------------------------

vi main.tf

provider "aws" {
  region = "ap-south-1"
}

data "aws_vpc" "default" {
  default = true
}

resource "aws_instance" "example" {
  ami           = "ami-08ee1453725d19cdb"
  instance_type = "t2.micro"
  subnet_id     = data.aws_vpc.default.id
}


data "aws_s3_bucket" "example_bucket" {
  bucket = "test-lala-ola-la"
}

output "bucket_arn" {
  value = data.aws_s3_bucket.example_bucket.arn
}


-- terraform apply --auto-approve

-- terraform destroy  --auto-approve



CONDITIONS
===========

vi main.tf

variable "aws_region" {
  description = "The region in which to create the infrastructure"
  type        = string
  nullable    = false
  default     = "change me" #here we need to define either us-west-1 or eu-west-2 if i give other region will get error
  validation {
    condition = var.aws_region == "ap-south-1" || var.aws_region == "eu-west-1"
    error_message = "The variable 'aws_region' must be one of the following regions: ap-south-1, eu-west-1"
  }
}

provider "aws" {
  region = "ap-south-1"
 
   
 }

 resource "aws_s3_bucket" "dev" {
    bucket = "statefile-configuresss"
   
 
}


=================================================================

If you accidently deleted main.tf and have only state file, we can recover the code

terraform show -no-color terraform.tfstate > recovered.tf


or use terraformer

====================================================================



TERRAFORM CLOUD: used to create resourec form gui.

1. create account
2. create organization
3. create workspace
4. add vsc -- > GitHub -- > username & password -- > select repo
5. start new plan
7. variables -- > add var -- > env vars -- >

-----------------------------------------
\How to Fix Drift?

âœ… Reconcile via Terraform
Run terraform apply to bring infrastructure back in sync.

âœ… Manually Adjust Terraform Code
If manual changes were intentional, update main.tf to match the current infrastructure.

âœ… Use terraform import for External Changes
If new resources were manually created, import them into Terraform:

terraform import <resource_type>.<resource_name> <resource_id>
âœ… Destroy and Recreate If necessary, destroy and recreate the resource:


terraform taint <resource_name>

terraform apply

Preventing Drift

ðŸ”¹ Use Terraform Cloud or Remote State Locking
ðŸ”¹ Enable Sentinel Policies to Block Manual Changes
ðŸ”¹ Implement IaC Best Practices (Avoid Direct Manual Changes)

---------------------------------

Terraform Vault: no practise
===============

HashiCorp Vault is a tool designed to securely store and manage sensitive information such as secrets, passwords, certificates, and API keys.

Terraform can be integrated with Vault to dynamically retrieve and manage secrets as part of your infrastructure provisioning process.

sudo yum install -y yum-utils

sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo

sudo yum -y install vault

systemctl status vault

systemctl start vault

vault server -dev

vault secrets enable -path=secret kv

vault kv put secret/mysecret password="supersecretpassword"